%Ondrej CV.
%URL for CTT - short!!!!
%Status of Nott JES
%Vat 

%WP relationships and methodology (katya)
%Do WPS say waht they need to, eg wP5 verifies WP1,2,6
%WP7 is still POC.
%In risk ok .. too much, too little? Feasability. Structured with
%acheivable POCS for overall ambitious result with individual ambition too.
%WP distinct. Relentless constructivity, Cubical TT, Contianers,
%Frank, HoTT in HoTT, ??, ??, UoM
%check leadership and seconds, esp WP4,5
%All WPS are POCs for our technology.
%Whole > sum of parts. Each WPa small detailed step but
%collectively. In feasability.
%WP5 and higher IR - needed or nice.


%checks
%====
%check jes for log rels.
%letters, EPSRC Review forms, quotes
%EPSRC Impact guidance.
%Brotherstone


%Why no one else (JoR)
%Indivdual small steps are being taken
%==========
%Developed by mathematicians
%rebuilding it - our track record of converting maths to PL
%Why has no one done it before. Have we balls or insight

%drafts out of track record
%Unify JoR, WPs and TRs
%potential vs achieved
%We want to do impact
%interdisciplinary
%No overstretch (POC)
%Collabs time
%Dissing others (AS + PW). We are formal methods (GC)
%TXA M$ studentship. 
%Management by planning
%Coquand et al. Ghani, Neil Ghani, %Spell, fullsptop
%check jes
%References consistency of citation and in bibliogrpahy
%Axomatic vs type theoretic HoTT

\documentclass[a4paper,11pt]{article}

\usepackage[top=2cm, bottom=2cm, left=2cm, right=2cm]{geometry}

\usepackage{mathptmx}
\usepackage{epsf}           %\input{epsf}
\usepackage{amsfonts}
\usepackage{amstext}
\usepackage{amssymb}
\usepackage{url}
%\usepackage[dvips]{graphics}
\usepackage[dvips,pdftex]{graphicx}
\usepackage[dvips,all]{xy}
\usepackage{multicol}
\usepackage{natbib}
\setlength{\bibsep}{0.0pt}

\usepackage{hyperref}

%\newlength{\extraplusheight}
%\newlength{\extrapluswidth}
%\setlength{\extraplusheight}{4.7cm}
%\setlength{\extrapluswidth}{4.7cm}
%\addtolength{\textwidth}{\extrapluswidth}
%\addtolength{\textheight}{\extraplusheight}
%\addtolength{\oddsidemargin}{-.5\extrapluswidth}
%\addtolength{\evensidemargin}{-.5\extrapluswidth}
%\addtolength{\topmargin}{-0.5\extraplusheight}
\setlength{\parindent}{0 pt}
\setlength{\parskip}{.5ex}

\newcommand{\eg}{{e.g.}\ }

\newcommand{\Int}[1]{[\![ #1 ]\!]}
\newcommand{\malign}[1]{\begin{array}[t]{@{}l@{\;}l@{}l@{}} #1 \end{array}}
\newcommand{\logrel}[2]{\Delta_{#1,#2}}
\newsavebox{\fminibox}
\newenvironment{fminipage}
 {\begin{lrbox}{\fminibox}\begin{minipage}{8cm}\vspace*{-2ex}}
 {\\[-2ex]\vspace*{-2ex}\end{minipage}\end{lrbox}\noindent\centerline{\fbox{\usebox{\fminibox}}}\vspace{0.5ex}}   

%\setlength{\parindent}{0.15in}
%\setlength{\parskip}{0.3ex}

% Discourage unnecessary hyphenation.
\sloppy\hyphenpenalty 4000

\newcommand{\ra}{\rightarrow}
\newcommand{\A}{\mathcal{A}}
\newcommand{\E}{\mathcal{E}}
\newcommand{\C}{\mathcal{C}}
\newcommand{\B}{\mathcal{B}}
\newcommand{\Set}{\mbox{{\sf Set}}}
\newcommand{\Nat}{\mathit{Nat}}
\newcommand{\Alge}[1]{\mathit{Alg}_{#1}}
\newcommand{\hash}{\#}

\begin{document}

\thispagestyle{plain}
\begin{center}
  {\Large {\bf Homotopy Type Theory: Programming and Verification}}\\[1ex] 
\vspace*{-0.1in}

%  {\Large \bf Case for Support}\\[1ex]
  \rule{140mm}{.5mm}\\[2ex]
\end{center}

\noindent
{\bf \Large Part 1A: Previous Research \& Track Record}

\textbf{Professor Neil Ghani.} Neil Ghani was appointed to a
Professorship in 2008 at the University of Strathclyde where he
founded the Mathematically Structured Programming (MSP) group. His
research has focussed on a number of topics directly related to the
subject of the current proposal, \eg i) his work on logical
relations~\cite{neil2014relParamDep} is directly related to WP1 and
WP2 which develops semantic and syntactic presentations of Homotopy
Type Theory (HoTT); ii) his work on data types
(containers~\cite{alti:cont-tcs}, quotient
containers~\cite{alti:mpc04}, indexed
containers~\cite{altenkirchGhaniHancockMcBrideMorris:indexedContainers}
and
induction-recursion~\cite{ghani:fibredIR})
%~\cite{alti:mpc04,altenkirchGhaniHancockMcBrideMorris:indexedContainers,alti:cont-tcs}
is directly related to WP3 which develops the theory of higher
inductive types; iii) his work on the semantics of
effects~\cite{atkeyGhaniJacobsJohann:effects} is directly related to
the application of HoTT to effects in WP4; and iv) his work on Units
of Measure (via an Impact Accelerator Account grant held in
collaboration with Microsoft) directly relates to WP8 which applies
HoTT to computing with algebraically indexed types. More generally, Neil
Ghani is a world expert on the use of semantic structures to drive the
development of type theory and programming languages, exactly the
methodology to be followed in this proposal.

Professor Ghani has attracted \pounds 1.7M in research funding
comprising \pounds 1.3M as PI on 8 grants and \pounds 400K as CoI in 2
grants.  Indeed, results obtained during his following EPSRC grants
feed directly into this proposal: Theory And Applications of Induction
Recursion (EP/G03298X/1), Reusability and Dependent Types
(EP/G034109/1), Logical Relations for Program Verification
(EP/K023837/1), and Theory and Applications of Containers
(EP/C511964/2). The first two of these were 3-site grants similar in
nature to this proposal and thus demonstrates Ghani's track record in
successfully managing distributed grants of this size. More generally,
Ghani has successfully supervised five PhD students, is supervising
three more, and has supervised four RAs. He organises the ScotCats
seminar series, and will host the next UK HoTT meeting in January
2015, both of which put him in touch with other experts in HoTT. He is
a member of the EPSRC Peer Review College and is a SICSA theme leader
in Complex Systems Engineering. Finally, his Impact Accelerator
Account demonstrates a track record generating impact from EPSRC
funded research --- see {\em Pathways to Impact} for details.

For further information, see~\url{http://www.cis.strath.ac.uk/~ng}.

\textbf{Dr Conor McBride.} Conor McBride received his PhD from the
University of Edinburgh in 1999 for his work on dependently typed
programming. After this, he worked as an RA at the Universities of
Durham and Nottingham before becoming a lecturer at the University of
Strathclyde in 2008. His work on the foundations and implementations
of non-dependently and dependently typed
programming~\cite{viewftl,alti:ott-conf,easy}
has become seminal, both via his own programming language
Epigram and via his work with the Agda, Coq, and Haskell teams. He is
now widely regarded as a leader of his field as illustrated by his
widely cited papers (\eg ~\cite{viewftl} has been cited 320 times) and
invitations to keynote addresses at conferences. Taken with his
experience developing and implementing Observational Type Theory (a
proof irrelevant form of HoTT)~\cite{alti:ott-conf}, he is
thus the ideal person to lead WP6 and WP7. Furthermore, Dr McBride's
work on containers~\cite{alti:mpc04}
%, induction-recursion~\cite{alti:tlca13-small-ir}
and effects~\cite{conor:frank} feed into WP3 and WP4 while his experience
in dependently typed programming will feed into WP8.

Dr McBride has attracted \pounds 600K in research funding comprising
\pounds 100K as PI on an EPSRC grant, \pounds 100K as a PI on a
Microsoft grant and \pounds 400K as CoI on 2 EPSRC grants. Not only
are all of these grants of direct relevance to this project, but they
show both his experience of working in large distributed grant
projects and that our plans for generating industrial impact through
Microsoft are built on solid and successful pre-existing
foundations. Connections with Microsoft will be further deepened by Dr
McBride working at Microsoft over the summer of 2014.  Dr McBride has
also supervised two PhD students, 2 postdocs and currently supervises
a further two PhD students. He also leads the MSP group.

For further information,
see~\url{https://personal.cis.strath.ac.uk/conor.mcbride/}.

\textbf{Host Institution: The University of Strathclyde.} The MSP
group at the University of Strathclyde is an ideal venue for
conducting this research. Led by Dr Conor McBride, the group includes
Professor Neil Ghani, Dr Clemens Kupke, Dr Ross Duncan as well as two RAs and seven PhD students. The MSP group's vision is to use
mathematics to understand the nature of computation, and to turn that
understanding into the next generation of programming languages ---
exactly the methodology of this proposal. This proposal will thus both
benefit from, and benefit, the MSP group. Central Scotland
is also home to many vibrant research groups linked via  the Scottish
Informatics and Computer Science Alliance (SICSA). The MSP group also
is active in other Scottish meetings, including ScotCats and SPLS, and
regularly organises international events.

\newpage \textbf{Dr Thorsten Altenkirch.}  Thorsten Altenkirch is a
Reader at the University of Nottingham where he founded the Functional
Programming Laboratory with Graham Hutton in 2008. Altenkirch's
work on type theory and applications of category theory
in computer science is of direct relevance to this project, \eg i) he has
published several papers on both HoTT and the computational treatment
of equality
\cite{altenkirch:extSetoids,alti:ott-conf,alti:csl12,alti:tlca13-hedberg}
which feed into WP2; ii) his work on data types 
(containers~\cite{alti:cont-tcs}, quotient
containers~\cite{alti:mpc04}, indexed
containers~\cite{altenkirchGhaniHancockMcBrideMorris:indexedContainers}
and
induction-recursion~\cite{ghani:fibredIR})
%~\cite{alti:mpc04,altenkirchGhaniHancockMcBrideMorris:indexedContainers}
feeds into WP3; iii) his work on
effects~\cite{alti:catind2} feeds into WP4; and iv) his programming
language $\Pi\Sigma$~\cite{alti:pisigma-new} feeds into WP6. He
has attracted \pounds 1M in research funding,
comprising~\pounds650K  as PI in four EPSRC grants, \pounds240K
as CoI in two EPSRC grants,  a \pounds160K EU fellowship and
one \pounds 60k Microsoft PhD 
studentship (showing a track record of interacting with
Microsoft). Especially relevant for this project is
Observational Equality For Dependently Typed Programming
(EP/C512022/1), Theory And Applications of Induction Recursion
(EP/G03298X/1), Reusability and Dependent Types (EP/G034109/1) and
Theory and Applications of Containers (EP/C511964/2).  Altenkirch,
Ghani and McBride collaborated successfully on the third grant above
demonstrating their effectiveness as a team. More
generally, Altenkirch is one of the leading researchers in HoTT as
witnessed by his fellowship at the Institute of Advanced Study in
Princeton during the Special Year on HoTT in 2013. There, he
coauthored the standard reference on the subject~\cite{hott-book}.  He
has given invited lectures on HoTT (at HDACT in Ljubljana in 2012, at
the Curien-fest in Venice in 2013, at MSC in Lyon, and at the Institut
Henri Poincar\'e in Paris in 2014 \cite{txa-ihp14}).

For further information, see~\url{http://www.cs.nott.ac.uk/~txa}.

\textbf{Host institution: The University of Nottingham.}  The
University of Nottingham is a leading UK University 
and its School of Computer Science was ranked 8th in the last RAE. The Functional Programming Lab (FP Lab)
is one of its major research groups, with an international
reputation for formally-based approaches to software
construction and verification.  It comprises four
academic staff: Professor Graham Hutton, Dr Thorsten Altenkirch, Dr
Venanzio Capretta, and Dr Henrik Nilsson, and nine PhD students.
The group has received~\pounds1.5M of EPSRC funding over fourteen
projects, and has twelve completed PhD students.
The FP Lab provides a highly stimulating research environment,
holds weekly research seminars, and is also a leading participant in the MGS
--- a collaboration with Leicester and Birmingham offering training
to PhD students.
\noindent

\textbf{Dr Nicola Gambino.} Nicola Gambino received his PhD in
Computer Science from the University of Manchester in 2002. After
carrying out postdoctoral research, he became an Assistant Professor
in Mathematical Logic at the University of Palermo in 2008. Since
2012, he is an Associate Professor in Pure Mathematics at the
University of Leeds. Nicola Gambino is one of the leading researchers
on HoTT; in particular, his combination of expertise in type
theory~\cite{GambinoN:gentti}, category theory~\cite{GambinoN:polfpm}
and homotopical algebra~\cite{GambinoN:homl2c,GambinoN:weilsh} allowed
him to obtain, in collaboration with Richard Garner, one of the very
first results relating type theory and homotopy
theory~\cite{GambinoN:idetwfs} and, in collaboration with Steve Awodey
and Kristina Sojakova, a characterisation of inductive types in
HoTT~\cite{awodeyGamSoja:indTypesInHTT}. These results feed directly
into WP1,2 and 3. He has attracted over \pounds500K in research
funding, including \pounds 209,959 as PI in a grant by the US Air
Force Office for Scientific Research on the relation between HoTT and
higher-dimensional category theory, \pounds 304,070 as CoI on a grant
by the Templeton Foundation on proof theory, and \pounds 66,191 as PI
on an EPSRC Postdoctoral Fellowship in Mathematics, held at the
University of Cambridge~(GR/R95975/01).  Nicola Gambino has a
consistent record of invited lectures at international conferences,
{e.g.}~at the 2010 Logic Colloquium in Paris and at the joint 2014
RTA-TLCA conference in Vienna. He held visiting positions at several
prestigious research centres, including the Institut Mittag-Leffler
(Stockholm), the Fields Institute (Toronto), the Institute of Advanced
Study (Princeton), where he worked with Fields Medalist Vladimir
Voevodsky (inventor of the Univalence Axiom), and at the Institut
Henri Poincar\'e (Paris) for the special trimester on Semantics of
Proofs and Certified Mathematics.  He is an editor of the journal
Mathematical Structures in Computer Science.

For further information,  see~\url{http://www.maths.leeds.ac.uk/~pmtng}.

\textbf{Host Institution: The University of Leeds.} The University of
Leeds is a leading UK university providing
excellent facilities for research. The School of Mathematics hosts the
Mathematical Logic group, including seven members of staff, four
research fellows, and nineteen research students. The group has a
vibrant research profile; it frequently organises
international conferences and runs several regular activities,
including a weekly Mathematical Logic Colloquium and specialist
seminar series on model theory, proof theory, and computability
theory. The Mathematical Logic group has been consistently funded by
EPSRC and international agencies, and is already active on Homotopy
Type Theory. In particular, we intend to collaborate closely with
Professor Michael Rathjen, who is currently PI
on a 3-year EPSRC grant on proof-theoretical aspects of HoTT. 

\newpage
\noindent
{\bf \Large Part 2: The Proposed Research and Its Context}

\vspace*{-0.23in}

\begin{center}
\rule{170mm}{.5mm}
\end{center}

\vspace*{-0.4in}

\section{Introduction}\label{sec:intro}

\vspace*{-0.1in}

{\bf Formal Verification.} The cost of software failure is truly
staggering\footnote{see the sections on National Importance and
  Pathways to Impact.}. There are many successful approaches to
software verification (\eg testing, model checking etc), with the most
rigorous offering mathematical guarantees of software
correctness. However, the complexity of modern software means that
hand-written mathematical proofs can be untrustworthy and this has led
to a growing desire for machine-checked proofs of software
correctness. Several decades of pioneering work in the UK and
elsewhere have culminated in systems such as Agda, Coq, Epigram, HOL,
Idris, Isabelle, NuPRL, Twelf, and the Trellys project which are
having significant impact, \eg Coq won both the 2013 ACM Software and
the 2013 SIGPLAN Programming Languages Software awards while HOL is
used extensively by Intel~\cite{harrison:sfm}. The technology behind
these systems is also exploited by more mainstream languages with
significant industrial deployment such as Haskell, OCaml, Scala and
F\#. 

{\bf The Problem with Equality:} However, such systems have
fundamental limitations, \eg when programming with quotients
(identifying objects upto an equivalence relation), supporting
abstraction (invariance under different representations of the same
structure) and extensional reasoning (proving that programs with the same
behaviour are the same). These limitations are manifestations of
an even more fundamental problem unresolved for over 40
years, namely the lack of a satisfactory computational theory of
equality. The problem is that, to be computational (\eg to allow proof
checking), it is not enough to know when things are equal and we must
instead know how we proved such an equality. And then one needs to
address the question of when such proofs are equal! This leads to a
intricate higher dimensional structure which we have so far not
understood.

{\bf Homotopy Type Theory:} Fields medalist Vladimir Voevodsky
introduced HoTT to enable machine checking of mathematical proofs.
HoTT is a revolutionary new synthesis of type theory and homotopy
theory --- types are regarded as \emph{spaces}; terms are
\emph{points} within a space; and equality is represented by
\emph{paths} in a space. Decades of research in homotopy theory has
understood the structure of such paths and HoTT uses this structure as
the basis of a new theory of equality. Excitingly, within homotopy
theory, one naturally studies higher homotopies of paths between paths
and this gives exactly the higher dimensional structure of equality we
lacked.  HoTT is widely regarded as a huge advance, \eg articles on
HoTT have appeared in the New Scientist and in Scientific American,
the HoTT book~\cite{hott-book} is on the ACM's list of notable books
of 2013, thirty of the world's leading researchers spent a year
developing HoTT at Princeton's Special Year on HoTT, and Prof Awodey
was recently awarded a complementary grant of $\$ 7.5$M to redevelop
the entire foundations of mathematics using HoTT.


{\bf The Project:} We believe HoTT has just as much potential to
transform the foundations of programming and will leap
ahead of the field via the following
synthesis of theoretical, applied, and impact-focussed research.

$\;\;\; \;\;\;$ {\em Foundations.} 
While most of our understanding of HoTT is classical, and hence
cannot be used to develop programming and verification
tools, the recent cubical sets model~\cite{BezemM:cubsmt,nominal} %is constructive and
strongly suggests that HoTT has a purely constructive
presentation. We will develop both specific constructive models and a
general constructive model theory of HoTT, and complement these models
with type-theoretic presentations of them (WP1,2,3).

$\;\;\;\;\;\;$ {\em Programming Language and Verification Tools.} The key
  deliverable of the second strand of our research is a HoTT-based
  programming language which simultaneously acts as a verification
  environment. This will translate the fundamental innovation of HoTT
  into a fundamental innovation within programming languages,
  influencing the development of all current and future systems in
  this area (WP5,6,7).

  $\;\;\;\;\;\;$ {\em Generating Impact.} Developing new and
  fundamentally better ways to construct formally verified software is
  not just an end in itself, but is also a key prerequisite for
  engaging others to do the same.  To ensure this, we will produce a
  number of case studies with industrial collaborators from Microsoft so users can
  learn from, and experiment with, our results. Their practical
  experiences will also feed back into our research (WP4,8).

  {\bf Quality, Ambition, Adventure and Distinctiveness:} Our goal of
  transforming the foundations of programming languages by delivering
  the first of a new breed of HoTT-based programming languages
  demonstrates our ambition. Quality is demonstrated by
  the depth and range of our state-of-the-art ideas and by
  the stature of our collaborators. The proposal's adventure is its
  interdisciplinary nature in breaking down boundaries between
  homotopy theory, theoretical computer science, programming languages
  and verification. This is reflected in its scope,
  ranging from fundamental research (WP1,2,3) to programming languages
  and verification (WP5,6,7) to impact generation via case studies
  (WP4,8). As for distinctiveness, neither we nor our collaborators
  know of other groups who share our ambition to construct HoTT-based
  programming languages and verification tools, let alone apply them
  to specific case studies. The distinctiveness of our goals is
  matched by the distinctiveness of our ideas and expertise covering
  logical relations, containers, observational type theory, cubical
  type theory and dependently typed programming.  Overall, our central
  belief is that i) this research clearly ought to be done for both
  its scientific and impact value; and ii) our experience in both the
  sophisticated mathematical foundations of HoTT, and in the intricate
  engineering techniques of implementation makes us the ideal team.
  Indeed, the breadth of this research prevents most others from undertaking
  this project.

%competancies, ideas and connectons with HoTT's key
%  developers make us the ideal team. 



%

% to
%  undertake this proposal when many others couldn't. 


% coolabs?
%hard maths + hard implementation 
%Constructive models



%This is crucial ---
%  while we benefit from being part of the worldwide HoTT community, we
%  also have great distinctiveness in our cumulative competencies,
%  experiences, and hence approach.

\vspace*{-0.1in} 



\vspace*{-0.1in} 
\section{Scientific and Technological Background.}
\vspace*{-0.1in} 

{\bf Programming Languages.} Abstraction is essential in programming
as identifying common structure ensures code is clear, clean, and
concise. This leads to high-level programming languages with
expressive type systems capable of closing the gap between what
programmers know about their code and what their types can express.
The current state-of-the-art are the {\em dependently typed
  programming languages} where the type of a program can express a
continuum of precision --- from basic assertions up to a complete
specification --- about its behaviour. This proposal will develop the
first of a new breed of such languages which offer a powerful yet
computationally tractable notion of equality, thereby achieving the
the goal of programming up to invariance of representation.


{\bf Program Verification.} While the advantages of the certainty
afforded by mathematical proof has been recognised for centuries, this
certainty is undermined by the risk of making mistakes in
proofs. The advent of computers raised the possibility once more of
achieving in practice the promise of mathematical certainty. This
potential is now coming to fruition, \eg systems such as Coq have been
able to formally verify both large mathematical theorems such as the
4-Colour problem, and large software systems such as the CompCert
C-compiler. However, these systems are not {\em extensional}:
behaviourally indistinguishable objects cannot be proven to be the
same, and this fundamental problem significantly weakens usability of the
system. We will transform the area by producing a system where
objects with the same behaviour can indeed be proven equal.


{\bf Type Theory.} Type theory underlies formal verification systems
and programming languages. The Curry-Howard correspondence asserts
that programs and proofs are actually the same thing, \eg proofs are
just particular forms of programs --- developing sophisticated type
theories thus advances both the fields of programming and
verification. Another major advance was Martin-L\"of's realisation
that type theory needed to cover equality --- however, although
extensional Martin-L\"of Type Theory produced a strong equality, it
had the fundamental flaw that type checking was undecidable. He then
formulated intensional Martin-L\"of Type Theory (MLTT), but its
equality proved to be too weak, \eg pointwise equal functions cannot
be proven equal. Defining a strong yet computationally tractable
equality has remained unresolved for 40 years --- HoTT is so exciting
and attracts so much attention precisely because it offers a solution
to this most fundamental of problems.

{\bf Observational Type Theory (OTT) and Logical Relations:} OTT was
proposed by Altenkirch and McBride~\cite{alti:ott-conf} as a step
towards such a stronger equality. While the equality type of MLTT is
defined uniformly over types, OTT defines an extensional and decidable
equality by induction on the type structure. However, the {\em
  equality of types} themselves is rigidly structural, preventing
conversion of proofs about one type into proofs about an equivalent
type. As HoTT can be seen as a proof-relevant extension of OTT, our
experience in OTT will be invaluable. Logical relations also use
induction on type structure to define not equalities, but rather
relations, over all types. They have already been
used~\cite{licataHarper:canonicity2d} to study a truncated form of
HoTT. Further, cubical sets~\cite{BezemM:cubsmt} arise naturally when
one extends logical relations to higher dimensions via the pattern of
set, relation, relation between relations etc. Ghani's EPSRC-funded
research on logical relations will be used to inject advanced logical
relations ideas, \eg higher dimensional logical relations, throughout
the project.


{\bf Homotopy Type Theory.} HoTT introduces new ideas, \eg i) the new
Univalence Axiom, introduced by Fields medalist Vladimir Voevodsky,
asserting (roughly) that isomorphic types are equal; and ii)
\emph{higher} inductive types (HITs) which go beyond the usual
tree-like data types, \eg while lists are an inductive type, braids
are lists with extra paths identifying lists up to twisting of any
element past its neighbours, and bags are braids with
paths-between-paths identifying braidings which yield the same
permutation.  The interpretation of closed expressions of HoTT within
the cubical sets model~\cite{BezemM:cubsmt, nominal} proves the basic
feasibility of computing with Univalence.  However, much work remains:
we need a type theory (as opposed to a model) within which closed
expressions are interpreted.  Definitional equalities lost by the
cubical interpretation (such as the computation rule for equality
types) must be recovered. And, we need to build programming
language and verification tools, and demonstrate their value via case
studies --- exactly the central and distinctive core of this proposal.




\vspace*{-0.2in}

\section{Methodology and Research Programme}
\vspace*{-0.1in}

Our overall methodology harnesses i) our distinctive ideas and
competencies detailed below and within  our track records and
the {\em Justification of Resources}; ii) our ongoing dialogue with
our world-leading collaborators, and iii) the workshops we 
organise to foster interaction. Additionally, each work package has
its own problem description, specific methodology, risk analysis, 
concrete deliverable, and  associated collaborator. 

%This ensures both rapid
%feedback on our results and that we are aware of advances elsewhere. 
%The
%project is structured as follows.

{\bf WP1: Semantic Foundations of HoTT.}  A proper model theory for
HoTT is essential because i) a general model theory guides the design
of different presentations and implementations of HoTT; ii) models of
HoTT provide algebraic techniques to reason about the correctness of
implementations which complement syntactic techniques; and iii)
specific implementations of HoTT can be proven sound by giving a
specific model of them.  These models need to be constructive so that
all programs reduce to a normal form.  We will: i) analyse existing
models ({e.g.}  groupoids~\cite{HofmannM:groitt}, simplicial
sets~\cite{KapulkinC:simmuv}, cubical sets~\cite{BezemM:cubsmt}) and
isolate exactly how they ensure constructivity or where they fail to
do so --- in the latter case, we will attempt to constructivise them;
ii) building on this, we will develop a general model theory for HoTT
by isolating the essential features of these models and by adapting
known methods to construct Quillen model structures to the setting of
HoTT ({c.f.}~\cite{ShulmanM:uniidh}, which however does not cover the
cubical sets model).  The challenge is to take the recent advances in
axiomatizing models of type theory ({e.g.}~\cite{AwodeyS:natmtt}) and
blend in the additional structure of HoTT. In terms of risk, i) is
certainly achievable as it involves only the analysis of existing
concrete models, while ii) is a more ambitious goal. Nevertheless, our
expertise on semantics of type theories~\cite{neil2014relParamDep},
homotopical algebra~\cite{GambinoN:homl2c,GambinoN:weilsh}, and
$\omega$-groupoids~\cite{alti:csl12} makes even this ambitious goal
feasible. {\em Deliverables: A broad collection of models of HoTT
  mapping the design space of its syntactic presentations.
  Collaborator: Steve Awodey.  }



% {\bf WP1: Semantic Foundations of HoTT:}  We
% seek semantic insights into HoTT akin to those provided by Cartesian
% closed categories for the simply typed
% $\lambda$-calculus.  A constructive model theory for HoTT is essential because: i)
% specific implementations of HoTT can be proven sound by giving a specific
% models of them; ii) 
% %since we don't know a priori what the best implementation
% %of HoTT will be, 
% a general model theory of HoTT will implicitly predict, and thereby
% guide, the design space of different presentations and implementations
% of HoTT; and iii) models of HoTT will provide algebraic techniques to
% reason about the correctness of implementations which complement
% syntactic techniques. These models need to be constructive so that
% programs, even those using Univalence, will compute. While the
% standard model of HoTT-based upon simplicial sets is not constructive,
% Coquand et al.'s recent cubical set model is constructive and 
% has thus opened the door to a more general model theory.

% %Joyal
% %Back ground : Qullien model structures

% We will attack this problem from the following directions: i) we will
% analyse existing models (cubical sets, groupoids, strict
% $\omega$-groupoids, simplicial sets, globular sets) to isolate exactly
% how they ensure constructivity, or (where they fail to do so) how to 
% constructivize them; and ii) informed by i),
% we will develop a model theory for HoTT by both adapting known methods to
% define Quillen model structures (such as the small object argument)
% to the constructive setting and by showing how one can build  new
% constructive model structures from old (\eg by
% slicing). A promising starting point for a constructive
% version of the small object argument comes from Garner's work, where
% it is related to the construction of free monads. In terms of risk,
% i) is certainly achievable since it involves only the analysis of
% existing concrete models, while ii) is a more ambitious
% goal. Nevertheless, our expertise on semantic models of parametricity \cite{neil2014relParamDep}, model
% categories (Gambino) and $\omega$-groupoids \cite{alti:csl12} makes even this
% ambitious goal feasible. Deliverables from WP1 will be a broad class
% of models of HoTT which considerably deepen our
% understanding and map out the design space of its 
% syntactic presentations.

% back ground work: NOMINAL SETS,



{\bf WP2: Univalent Type Theory.}  Possibly the biggest open problem
in HoTT is the lack of a type theory where key HoTT concepts
such as Univalence are validated computationally as opposed to axiomatically. Such a type theory must be proved to retain key
properties of traditional type theories such as strong normalisation,
decidability of definitional equality, and canonicity ({i.e.}~all
terms reduce to values). We must also establish the expressive power
of the associated equational theories, {e.g.}~by analyzing carefully
whether computation rules hold definitionally or
propositionally. Another key property (needed for WP5) is that these
type theories should be expressive enough to describe their own
models. These properties will be established either directly or via the theory
developed in WP1. We start with Altenkirch's observation \cite{txa-ihp14} that cubical
sets share many similarities with logical relations in replacing the
uniform identity type of intensional MLTT with a higher-dimensional
equality designed to fit the structure of types. Altenkirch's proposed
Cubical Type Theory~\cite{alti-ctt} formalises this idea by internalising logical
relations --- and adding Kan fillers --- so as to derive Univalence as a consequence. Indeed, the use
of internal logical relations distinguishes our approach from Brunerie
and Licata's (unpublished).  The models from WP1 will drive refinement of our design
until we have a canonical presentation of HoTT. Our preparatory
work~\cite{txa-ihp14}, and prior expertise in OTT
\cite{alti:ott-conf}, normalisation by evaluation and big-step
reduction \cite{alti:lics96}, %alti:ctcs95,alti:flops04,txa:jtait
strengthening definitional
equality~\cite{Allais:2013:NEN:2502409.2502411}, and logical
relations~\cite{neil2014relParamDep} ensures a high probability of
success.  {\em Deliverable: A
  type theory validating Univalence.  Collaborator: Vladimir
  Voevodsky.  } 



%once these higher-dimensional logical
%relations are internalised within the type theory, and augmented by
%Kan fillers, Univalence becomes provable {\em within} the type theory
%and thus need not be added axiomatically. The use of internal logical
%relations distinguishes 

% We will produce such a type theory by encapsulating the essential
% structure of the constructive models of WP1. This involves
% presenting the relevant structure via a {\em finite} collection of
% type and term constructors --- a particularly intricate task due to
% the higher dimensional structure of HoTT.

%We follow the
%practise in WP1 of managing risk in this workpackage by first aiming
%at the moderate goal of deriving specific presentations relating to
%specific models and then aiming for the more ambitious goal of
%integrating these presentations onto a unified framework.

% We will begin by developing Altenkirch's preliminary type theory for
% cubical sets, which both internalises parametricity and adds Kan
% fillers to the theory

{\bf WP3: Higher Inductive Types (HITs).}  We will accommodate HITs in
the semantics developed in WP1 and the syntactic framework of WP2. To
achieve this, we will first develop a universal HIT playing the role
for HITs that W-types play for ordinary inductive
types~\cite{alti:cont-tcs}. This is feasible as partial progress has
already been made: one can reduce HITs with higher dimensional
constructors to HITs with only 0- and 1-dimensional ones (using the
\emph{hub-and-spokes} construction~\cite{hott-book}). As further evidence, our
preliminary results suggest that quotient
containers~\cite{alti:mpc04} (special 1-dimensional HITs)
can be reduced to containers in
a homotopical setting (using ideas of Gylterud~\cite{gylterud:thesis}
and Kock~\cite{kock:groupoids}).  Another basic goal is to generate a
high-level syntax for HITs as an alternative to the universal HIT in
the same way that strictly positive types provide a grammar for
defining W-types~\cite{alti:cont-tcs}.  This will feed into WP7.  More
ambitiously, we will %-- time permitting --
investigate extensions such as coinductive HITs, 
inductive-inductive~\cite{alti:catind2} and
inductive-recursive~\cite{DS:indrec,ghani:fibredIR} HITs. The latter
would be useful in WP5 since it offers a more concise representation
of dependently typed syntax by introducing the representation of terms and 
 definitional equality at the same time.
%%fnf: the following is mentioned in WP7, and might fit better there:
%We will also investigate a pattern matching syntax for HITs; this is
%related again to WP7.
Our work on data
types~\cite{alti:cont-tcs,
altenkirchGhaniHancockMcBrideMorris:indexedContainers,
alti:catind2,ghani:fibredIR,GambinoN:polfpm,awodeyGamSoja:indTypesInHTT},
including our EPSRC grants on containers and induction-recursion, means
our first and second goals
are relatively risk-free,
especially since partial results already exist, 
% These show that results are available, and will also guide the way
% towards further results.
while progress on our more ambitious goal 
is not essential to the rest of the project. {\em Deliverable: A
  theory of HITs that is both foundational and can underpin the
  programming language developed in WP6 and WP7. 
Collaborator: Mike Shulman. 
}

{\bf WP4: Impact I --- Programming with Effects.}  Most programs
interact with their environments, but such \emph{effectful} programs
are inherently difficult to reason about.  Major advances
were the semantic 
modelling of effects by monads~\cite{moggi:monad}, the use of monads
to structure
effectful programs~\cite{wadler:monads} and the representation of many computational
monads as Lawvere Theories, i.e. their presentation as
effect-generating operations and
equations~\cite{PlotkinPower:Lawvere}. Unfortunately, the lack
of a satisfactory computational understanding of equality means that
one is forced to program not in the quotient algebra as desired, but
within the free algebra and then check (externally to the program)
that the quotient structure is respected.  With HITs, we can avoid
such a convoluted process --- we can program directly on the quotient
algebra, thus assert the correctness of the program within its type, and
hence efficiently and formally verify the program's
correctness. Concretely, we will formalise both Lawvere Theories
(using HITs to represent effectful computations) and their
mathematical algebra (e.g.\ tensor products, sums) in HoTT.  This will
simplify and extend i) McBride and Lindley's effect
handlers in Frank~\cite{conor:frank}; ii) Benton, Hofmann and Nigam's Abstract Effects
(see Benton's attached letter); iii) Brady's effects library for
Idris~\cite{brady:effects}; and iv) Bauer and Pretnar's treatment of
 effects in Eff~\cite{bauer:eff}.  Our work will use the type theory of
WP2, feed into the programming language of WP7, validate the
theoretical research done by RA1 and generate impact by showing the
relevance of HoTT to work by Benton at Microsoft. Basic results are low risk as,
conceptually, we need only stitch together the treatment of quotients
via HITs with that of effects via Lawvere theories.  However, more
advanced effects (\eg indexed effects) or the full-scale integration
of our results into WP7 is more ambitious. {\em Deliverable: A HoTT
treatment of Lawvere Theories.  Collaborator: Nick
Benton.  }


{\bf WP5 Formalisation of the Meta-Theory of HoTT.}  Since we need to
trust verification conducted within HoTT, the key properties of HoTT
must themselves be formally verified. Indeed, as Voevodsky pointed out
\cite{voevodsky-ias14}, the complexity of the higher dimensional
semantics of HoTT make a paper-based verification almost infeasible,
and certainly not trustworthy. We begin by formalising our current
understanding of HoTT using current tools such as Agda. In this less
ambitious initial phase we will take an an axiomatic approach to HoTT
(i.e., adding univalence and HITs as postulates). As the project
develops we will become more ambitous by i) formally verifying key
results across all our work packages; and ii) replacing the axiomatic
approach to HoTT with a computational one by switching from Agda to
the system developed in WP6 and WP7, thereby enabling a partial
formalisation of HoTT within itself. If possible, we will simplify our
formalisation by using inductive-recursive HITs of WP3.
Overall, WP5 will not only ensure the required level of trust in our
system and impact the formal verification community as the first
instance of formal verification in a {\em HoTT-based} environment, but
it will also establish that HoTT (like any foundational theory) can
describe its own meta-theory. Risk of failure in our basic goal is low
as we have begun formalising parts of HoTT~\cite{alti:csl12,AltenkirchLiRypacek14}. Further, our
experience of formalising the syntax of type theory in itself~\cite{mcbride:outrageous,ghani:fibredIR,alti:catind2} makes us well
positioned with respect to our more ambitious goals. Either way, no other WPs are
dependent on WP5. {\em Deliverable: Formally verified proofs of the
key properties of HoTT.  Collaborator: Matthieu Sozeau.  }

%cite conors outrageous

%We begin by formalising the existing model
%theory (\eg the cubical sets model) in conventional Type Theory using
%Agda --- this accompanies WP1. When moving on to the more syntactic
%approach of WP2, we plan to exploit HITs to achieve a feasible
%formalisation of dependently typed syntax. 
%We initially work
%with an axiomatic approach to HoTT (i.e., adding univalence and HITs as
%postulates), we will later use the results
%of WP6 and WP7 to replace these postulates with computational
%interpretations thereby enabling a partial
%self-certification of HoTT in HoTT.  %Moreover this will demonstrate
%the use of HoTT as a system for formal verification.
%While this approach seems unsound at
%first glance, it is reasonable since it is unlikely that a bug in
%the theory leads to an unsound formalisation of the metatheory.  

{\bf WP6: Implementing a Core Programming Language.} In order to
showcase the potential for HoTT-based programming languages to the
wider programming languages
community,%, and learn from their feedback,
we will produce an implementation of the type theory of WP2.  Because
of the amount of engineering work required to implement a programming
language we will not, at this stage, implement advanced features such
as a high-level syntax for datatypes, implicit arguments, or pattern
matching. Instead, we will produce a basic proof of concept
implementaton containing i) a prototypical implementation of a type
checker; ii) an interpreter for the type theory computing values for
closed expressions; and iii) incorporate the results from WP3 to
support a generic version of HITs based upon eliminators. We will
achieve this by adapting bidirectional type checking to the type
theory of WP2, to get syntax directed rules from which a type checking
algorithm can be read off. We will use Haskell as an implementation
language because we have had significant success with using Haskell to
implement similar type checkers for dependently typed languages,
including Epigram and
$\Pi\Sigma$~\cite{alti:checking,easy,alti:pisigma-new}.  In addition,
our prototypical implementation of OTT will be particularly
informative as it can be viewed as a precursor of HoTT.  Coquand et
al.'s interpretation of the axiomatic presentation of HoTT into their
cubical sets model also shows that our goal is feasible. {\em
  Deliverable: A typechecker and evaluator for core HoTT.
  Collaborator: Thierry Coquand.  }

% Coquand's and Huber's implementation of the cubical set model shows
% that our approach is feasible in principle and we plan to collaborate
% with them. However, we should be able to address particular issues
% such as the fact that certain definitional equalities don't hold in
% the cubical set model using the technology we have developed in the
% context of OTT \cite{alti:ott-conf} which is the subject of current
% work at Strathclyde.

% The main difficulty within this WP is that the implementation of
% higher dimensional type theories is a new area --- nevertheless our
% experience in the implementation of dependent type theories leads us
% to believe this is still of low risk. Having said that, there is some
% risk that the implementation takes much longer than expected: we will
% manage this by keeping the scope of the language small. {\bf Play up OTT and Parametricity (Johann)}

{\bf WP7: A High Level Programming Language.} We will make the
language developed in WP6 more usable by adding high-level syntax for
(higher) inductive types and by integrating technology such as
implicit arguments and pattern matching. There are real problems here
--- HoTT is inconsistent with both unlimited pattern matching and with
traditional termination checking. We will tackle the first problem by
finding minimal restrictions on pattern matching which do not destroy
consistency when combined with HoTT --- recent work by Cockx
\cite{cockx-without-k}, building on McBride~\cite{viewftl}, shows this is feasable. 
The problem with termination checking is that isomorphism of types
does not preserve subterm structure.
% and hence transporting a smaller
%recursive call across an isomorphism need not result in a smaller
%recursive call. 
Our proposal is to use the proof relevant nature of
HoTT to broaden the notion of size to include structural
information about equivalences. More ambitiously we aim to
solve the open problem of integrating pattern
matching with HITs. We will also explore the possibility of adding
interfaces to Idris, Coq and
Agda to increase impact by giving users of these systems access to
our results. To do this, we will work closely 
with the developers of
Idris (Brady), Coq (Herbelin, Sozeau) and Agda (Abel, Norell). {\em Deliverable: A high level
  HoTT-based
programming language.  Collaborator: Edwin Brady.  
}


 % A central question which needs to be
% answered is wether it is preferable to integrate our ideas with an
% existing system such as Agda, Coq or Idris or wether it is preferable
% to start from scratch. The advantages of the former approach is that
% we connect with significant user communities, can learn from their
% experience and avoid duplication of work. However, it is currently
% not clear wether this is feasible since it would affect the very
% core of these systems. Either way, we plan to collaborate closely with
% the developers of these systems to maximise compatibility and impact.


% This is the most ambitious of our work packages because, if successful,
% we would have produced a new state of the art programming language for
% software construction and verification. Given the current interest in
% HoTT, it would immediately attract attention of significant
% numbers. However, the volume of work required to develop a practical
% language makes this also the most risky WP. Nevertheless, if all we
% produce are proof-of-concept implementations of some high level
% features, leaving significant amounts of the implementation of a
% practical language to future work, then the project as a whole will
% still be a massive success because both the foundational, practical
% and engineering groundwork for a homotopical programming language will
% have been done. {\bf Libraries for doing HoTT in Agda}


% In Agda pattern matching is one of the main devices to support
% efective program construction ofr depndent types. However, unlimited
% pattern matching is incompatible with HoTT. Currently, in Akgda there
% is an adhoc implementation of a check that pattern matching is
% restricted so that UIP is not derivable. However, there is no clear
% theory or justification of the current implementation which also has
% been proven to be unsound in several instances. Our goal is to develop
% a notion of pattern matching which is consistent with HoTT and
% formally verify this fact. 

% In HoTT there are two orthogonal hierarchies of types indexed by size
% (i.e. universe level) and dimension (i.e. truncation level or h-level). We often
% want to quantify over types with a certain size or a certain dimension
% and we also want to be able to implement construction parametric in
% both. On the other hand we want to minimize bureaucracy and in
% particular automatically infer subtyping relations bewteen different
% levels. We will explore this new area which is essential to make HoTT
% usable in practice.



{\bf WP8: Impact II --- Programming and Invariance.} %The ultimate goal
%of the proposed research is to support software construction and
%verification via HoTT. 
We will validate the applied research done by RA2 and generate impact
by showing its relevance to work by Kennedy on Units of Measure at
Microsoft. This builds on Ghani's ideas~\cite{uom} and his Impact
Accelerator Account grant
with Kennedy.
%
%Our final work package returns to our original motivation:%
%we apply our research to real world software construction and
%verification and, by abstracting recurring patterns that
%arise, we take the first steps in software engineering with HoTT!
Details are given in {\em Pathways to
  Impact}. {\em Deliverable: A HoTT based generalisation of Units of Measure
Collaborator: Andrew Kennedy.
}

%Firstly, HoTT's ability to ``work up to isomorphism'' opens the way to
%program correctly using simple and straightforward reference
%presentations of data structures and then replace these presentations
%with more efficient equivalents at runtime. For instance, we shall
%deliver treatments of \emph{numbers} (simple unary representations $\cong$
%efficient binary representations), \emph{sequences} (cons-lists $\cong$
%inger-trees) and \emph{matrices} (vector-of-vectors $\cong$ sparse
%encodings). More generally, this opens the way for HoTT technology to
%be applied to situations where methodologies such as {\em views} and
%{\em worker-wrapper transformations} thereby influencing their
%development too. 
%A similar phenomenon occurs with data structures which store redundant
%information to improve access time, e.g., databases with indices to
%cut search, and records with cached values to avoid
%recomputation. {\bf ornaments}. The technical challenge will be to
%ensure that the efficiency savings are not dominated by the cost of
%computing with isomorphisms at runtime. Our idea is to use fusion to
%minimise the number of isomorphisms present at runtime, and to enable
%the compiler to work with intermediate representations to give fine
%grain control of the cost of the isomorphisms involved.  This will
%ensure that we maximize the regions within which we use the efficient
%representations, converting data only at the boundaries.  In effect,
%we will have improved on \emph{data abstraction}, the state-of-the-art
%tool for managing the craft of implementation, by supporting the
%refinement of concrete computational models of data.
%
%Secondly, HoTT's richer notion of equality ensures that different
%representations of a value can be exploited for efficiency purposes
%but cannot yield inconsistency. For example, whilst treelike
%structures can be given a canonical form, data such as individual graphs, cycles
%and multisets often have multiple representatives which should be
%treated the same by operations. Today's technology presents the
%dilemma of whether to expose the representation and risk inconsistent
%treatment or to hide behind an abstraction barrier which offers a
%fixed repertoire of consistent operations but inhibits us from
%exploiting the representation to develop unforeseen operations
%efficiently. At last HoTT offers us a precise deal: we can work with
%representatives, but we must work up to equality. 

\vspace*{-0.2in}

\section{Quality, Management, and Planning}

\vspace*{-0.1in}

{\bf Relevance to Beneficiaries.} Academic beneficiairies
are i) our collaborators who are also end-users of our research; ii)
the HoTT community will benefit from our programming languages
view of HoTT; iii) type theorists will benefit from new
foundations for their subject; and iv) the programming languages and
verification community will benefit from our tools making HoTT more
accessible. In the long term, beneficiaries extend to
programmers beginning with those interested in formal
verification and broadening out to the wider community. Our critical
mass of examples of verified code will offer them a gateway
into HoTT. See {\em Pathways to Impact}.
 
%\vspace*{0.02in}

{\bf National Importance.} % The software market is estimated at $\$
% 400$ billion per year~\cite{gartner}, and will grow significantly in
% real terms as software becomes ever more ubiquitous. 
The cost of software failure is truly staggering, \eg the annual cost
to the US economy alone of avoidable software errors was estimated
between $\$ 20$ and $\$60$ billion~\cite{grandchallenges} in 2002.  As
a result, both EPSRC and the UK Grand Challenges in
Computing~\cite{grandchallenges} recognise formal methods guaranteeing
software correctness as essential to the UK's economy. For example,
EPSRC is growing its funding in both programming languages and
verification. Our project contributes to both of these
areas. Similarly, Grand Challenge 6 seeks to create a ``body of code
that has been verified to the highest standards of rigour'' and that
is exactly the end goal of our project. Further, it sees i) ``a
unified framework'' to compare approaches to formal verification; ii)
``an integrated suite of tools" to achieve formal verification; and
iii) ``a repository of formally specified and verified code'' as its
three main objectives. The three strands of our research
(foundational, language development, and impact generation) contribute
significantly to each of these objectives in turn.  Indeed, formal
verification is an emerging industry the UK would do well to support,
especially given %the US support for HoTT, and
the French support of the Coq system. This is long lasting research,
\eg our tools are likely to become the cornerstone for the next
generation of high-level programming and verification
environments. Our research will thus have great impact over the next
10 to 50 years.  Over this time frame, we will also impact other
research areas by providing tools to formally verify results and
thereby increase trust in them. By increasing trust in software, our
research also feeds into the EPSRC Digital Economy theme, the Global
Uncertainties theme and contributes to cyber security.


{\bf Timeliness, Feasibility and Success Criteria.}  This research is
extremely timely: in addition to our results, there have been
ground-breaking recent advances~\cite{ShulmanM:uniidh,BezemM:cubsmt, nominal} and Awodey has just
been awarded a \$7.5M complementary grant applying HoTT to the
foundations of mathematics. Gambino is a coinvestigator on that grant,
while its key members (Awodey, Voevodsky and Coquand) are
collaborators here --- this ensures swift and seamless communication
between these projects.  Overall a successful outcome is very realistic
as evidenced by our track records and our competancies (see {\em
  Justification of Resources}), our ideas and by recent 
ground-breaking advances in HoTT which together act as
proof-of-concept for the proposal. The central importance of WP2 to the
overall proposal is reflected in the extra preparatory work for it~\cite{alti-ctt,txa-ihp14}.
The input of our collaborators and
the highly active HoTT community further increases the likelihood of
success. We are also {\em very well-balanced} in that Altenkirch,
Gambino and Ghani are fully versed in foundations, Altenkirch and
McBride are adept at the implementation of programming languages, and
Altenkirch, Ghani and McBride have independent collaborations with Microsoft. Our
collaborators are equally well-balanced across the 
proposal. Success criteria for each work package are given as clear
deliverables. The success criteria for the overall project are i) new
syntactic and semantic foundations for HoTT; ii) programming language
and verification tools for computing with HoTT; and iii) a code base
of programs written in, and verified by, these tools.  

% show applied researchers how HoTT aids their daily
%practice.

{\bf Planning, Risk, Management and RA Training:} Apart from clearly
planning the content, methodology, and success criteria of each work
package, and the inherent balance between risk and ambition within
them, we have also minimised risk {\em between} work packages by
ensuring the deliverables required to enable the project to proceed
are relatively low-risk --- see the {\em Gantt chart} for details on
this and on how the work packages interact, who will lead them, and
who will be secondary contributors. We will manage the project by i)
6-monthly team meetings; and ii) asking our collaborators to formally
review our progress after two years.  Our successful
track records of working together --- including managing similar
multi-institutional grants --- indicate this is the right level of
management. Research group meetings provide regular opportunities to
report on progress, generate new ideas, and integrate the RAs into the
local environments. Further training includes i) reading groups for
relevant papers; ii) ensuring the RAs play prominent roles in meetings
(eg UK HoTT, ScotCats, SPLS, MGS, FitA) we attend/organise; iii)
writing of papers and grant proposals; iv) leading research activities
and mentoring PhD students; and v) participation in the large and
active HoTT comunity. The RAs will thus be able to lead future
research/development work --- vital as programming languages research
requires more work than the active workforce can handle. The
project will thus have high impact in terms of training.




%\vspace{-0.15in}

%{%\small

%\newpage
%\begin{figure}
%\centering
%\includegraphics{Gantt.eps}
%\caption{Gantt chart depicting the order and division of work on workpackages}
%\end{figure}
%\newpage

\begin{footnotesize}
\begin{multicols}{2}
\bibliographystyle{plain}
%\bibliographystyle{abbrv}
%\bibliographystyle{plainnat}
\bibliography{proposal,alti,nicola}
\end{multicols}
\end{footnotesize}

% \begin{multicols}{2}
% \bibliographystyle{plain}
% \bibliography{proposal,alti}
% \end{multicols}{2}

\end{document}
